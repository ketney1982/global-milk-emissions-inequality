# Autor: Ketney Otto
# Affiliation: „Lucian Blaga” University of Sibiu, Department of Agricultural Science and Food Engineering, Dr. I. Ratiu Street, no. 7-9, 550012 Sibiu, Romania
# Contact: otto.ketney@ulbsibiu.ro, orcid.org/0000-0003-1638-1154

"""Auto-generate Methods Appendix in Markdown.

Reads the run manifest, validation report, and key summaries to produce
a self-contained markdown document describing the entire methodology.
"""

from __future__ import annotations

import json
import logging
from pathlib import Path

import pandas as pd

from methane_portfolio import config
from methane_portfolio.utils import causal_disclaimer

logger = logging.getLogger(__name__)

_TEMPLATE = r"""# Methods Appendix

> *Auto-generated by `methane_portfolio.report`.  Do not edit manually.*

---

## 1. Data Sources

- **Emission Intensity** (species-level): `{intensity_file}`
- **Species Structure** (shares): `{structure_file}`
- **Aggregate Intensity** (country-year): `{agg_file}`
{coverage_section}

---

## 2. Validation

Three accounting checks are performed:

| Check | Description | Tolerance | Status |
|-------|------------|-----------|--------|
| Share sum | $\sum_s w_{{cts}} = 1$ | {share_tol} | {share_status} |
| Milk totals | species sum = aggregate | rel_tol = {milk_tol} | {milk_status} |
| Mixture identity | $I_{{ct}} = \sum_s w_{{cts}} \cdot I_{{cts}}$ | {identity_tol} | {identity_status} |

Validation report: `outputs/validation_report.csv`

---

## 3. Shapley Decomposition

The change $\Delta I = I_{{c,{end_year}}} - I_{{c,{base_year}}}$ is decomposed using **exact two-factor Shapley values**:

$$\Delta_{{struct}} = \frac{{1}}{{2}} \left[ \sum_s (\Delta w_s) I_s^0 + \sum_s (\Delta w_s) I_s^1 \right]$$

$$\Delta_{{within}} = \frac{{1}}{{2}} \left[ \sum_s w_s^0 (\Delta I_s) + \sum_s w_s^1 (\Delta I_s) \right]$$

- **Reconstruction tolerance**: {recon_tol:.2e}
- **Global production-weighted structure effect**: {global_struct:+.6f} kg CO2e/t
- **Global production-weighted within effect**: {global_within:+.6f} kg CO2e/t

---

## 4. Bayesian Hierarchical Model

### Specification

$$\log(I_{{cts}}) \sim \text{{StudentT}}(\nu, \mu_{{cts}}, \sigma_s)$$

$$\mu_{{cts}} = \alpha_s + u_c + \beta_s (t - 2020) + \gamma_s \cdot \mathbf{{1}}[t \geq {regime_year}]$$

| Parameter | Prior |
|-----------|-------|
| $\alpha_s$ | $\mathcal{{N}}(\bar y, \sigma_\alpha)$ with $\sigma_\alpha \in [0.5, 2.5]$ |
| $\beta_s$ | $\mathcal{{N}}(0, 0.5)$ |
| $\gamma_s$ | $\mathcal{{N}}(0, 0.5)$ |
| $\sigma_s$ | $\text{{HalfNormal}}(0.5)$ |
| $u_c$ | $\text{{ZeroSumNormal}}(0, \tau)$ (centered, sum-to-zero) |
| $\tau$ | $\text{{HalfNormal}}(\sigma_\tau)$, $\sigma_\tau = \mathrm{{clip}}(\mathrm{{sd}}(\bar y_c), 0.15, 1.0)$ |
| $\nu$ | $\Gamma(6, 1)$ |

### Sampling

- Chains: {chains}
- Draws: {draws}
- Tune: {tune}
- Target accept: {target_accept}
- Seed: {pymc_seed}

{diagnostics_section}
{ppc_diagnostics_section}

---

## 5. Robust Portfolio Optimisation

$$\min_w \; \lambda \, \mathbb{{E}}[I'(w)] + (1-\lambda) \, \text{{CVaR}}_{{\alpha}}(I'(w))$$

Subject to:
- $\sum_s w_s = 1$, $w_s \geq 0$
- $\frac{{1}}{{2}} \| w - w_{{ref}} \|_1 \leq \delta$
- $w_s = 0$ for species not in current mix (unless expansion allowed)
- **Do-no-harm guard**: optimized mean intensity must not exceed baseline intensity

CVaR is computed via the Rockafellar-Uryasev linear relaxation.

### Default parameters

| Parameter | Value |
|-----------|-------|
| $\lambda$ | {lam} |
| $\alpha$ | {opt_alpha} |
| $\delta$ | {delta} |

{optimisation_scope_section}
{optimisation_transparency_section}

---

## 6. Uncertainty Propagation

- **Share uncertainty**: $w \sim \text{{Dir}}(\kappa \cdot w_{{obs}})$, $\kappa = {kappa}$
- **Intensity uncertainty**: Posterior draws ($n = {n_draws}$)
- Combined via joint sampling

---

## 7. Causal Guardrails

> {disclaimer}

All results are labelled as **accounting counterfactuals** (scenario-based portfolio reallocation).
No causal claims are made.

---

## 8. Reproducibility

- RNG seed: {rng_seed}
- PyMC seed: {pymc_seed}
- Run manifest: `outputs/run_manifest.json`

---

*Generated by methane_portfolio v{version}.*
"""


def generate_appendix(
    long_df: pd.DataFrame | None = None,
    output_dir: Path | None = None,
) -> Path:
    """Generate the Methods Appendix markdown document.

    Returns the path to the generated file.
    """
    out = output_dir or config.OUTPUT_DIR
    out.mkdir(parents=True, exist_ok=True)

    # Read validation report if available
    val_path = out / "validation_report.csv"
    share_status = milk_status = identity_status = "not run"
    if val_path.exists():
        val = pd.read_csv(val_path)
        for check, var in [
            ("shares_sum_to_1", "share_status"),
            ("milk_totals_match", "milk_status"),
            ("identity_I_eq_sum_wI", "identity_status"),
        ]:
            sub = val[val["check"] == check]
            if len(sub) > 0:
                n_pass = (sub["status"] == "PASS").sum()
                n_total = len(sub)
                status = f"PASS ({n_pass}/{n_total})"
                if n_pass < n_total:
                    status = f"FAIL ({n_total - n_pass} failures)"
                if var == "share_status":
                    share_status = status
                elif var == "milk_status":
                    milk_status = status
                else:
                    identity_status = status

    # Read Shapley global
    shapley_path = out / "shapley_global.json"
    global_struct = global_within = 0.0
    n_countries_shapley = 0
    if shapley_path.exists():
        with open(shapley_path, "r", encoding="utf-8") as f:
            sg = json.load(f)
        global_struct = sg.get("global_struct", 0.0)
        global_within = sg.get("global_within", 0.0)
        n_countries_shapley = sg.get("n_countries", 0)

    # Read diagnostics
    diag_path = out / "bayes_diagnostics.json"
    diagnostics_section = "*Bayesian model not yet fitted.*"
    ppc_diagnostics_section = ""
    if diag_path.exists():
        with open(diag_path, "r", encoding="utf-8") as f:
            diag = json.load(f)
        converged = diag.get("converged", "N/A")
        converged_relaxed = diag.get("converged_relaxed", "N/A")
        thresholds = diag.get("thresholds", {})
        diagnostics_section = (
            f"### Diagnostics\n\n"
            f"- Max R-hat: {diag.get('max_rhat', 'N/A')}\n"
            f"- Min ESS (bulk): {diag.get('min_ess_bulk', 'N/A')}\n"
            f"- Min ESS (tail): {diag.get('min_ess_tail', 'N/A')}\n"
            f"- Divergences: {diag.get('divergences', 'N/A')}\n"
            f"- Convergence flag (strict, R-hat<{thresholds.get('rhat_strict', 'N/A')}, "
            f"ESS≥{thresholds.get('ess_strict', 'N/A')}): {converged}\n"
            f"- Convergence flag (relaxed, R-hat<{thresholds.get('rhat_relaxed', 'N/A')}, "
            f"ESS≥{thresholds.get('ess_relaxed', 'N/A')}): {converged_relaxed}\n"
        )
        if diag.get("rhat_fail_params"):
            diagnostics_section += (
                f"- Parameters failing strict R-hat: {', '.join(diag['rhat_fail_params'])}\n"
            )

    ppc_diag_path = out / "bayes_ppc_diagnostics.json"
    if ppc_diag_path.exists():
        with open(ppc_diag_path, "r", encoding="utf-8") as f:
            ppc_diag = json.load(f)
        ppc_diagnostics_section = (
            "\n### Posterior Predictive Checks\n\n"
            f"- Residual mean: {ppc_diag.get('residual_mean', 'N/A')}\n"
            f"- Residual median: {ppc_diag.get('residual_median', 'N/A')}\n"
            f"- Residual trimmed mean (10%): {ppc_diag.get('residual_trimmed_mean_10pct', 'N/A')}\n"
            f"- Max |residual|: {ppc_diag.get('residual_max_abs', 'N/A')}\n"
            f"- 90% CI coverage: {ppc_diag.get('coverage_90ci', 'N/A')}\n"
            f"- Count |residual| > 3: {ppc_diag.get('n_abs_residual_gt_3', 'N/A')} / {ppc_diag.get('n_obs', 'N/A')}\n"
        )

    # Data dimensions
    n_countries_input = 0
    n_species = 0
    if long_df is not None:
        n_countries_input = long_df["country_m49"].nunique()
        n_species = long_df["milk_species"].nunique()
    n_countries_analysis = n_countries_shapley or n_countries_input
    n_excluded_analysis = max(0, int(n_countries_input - n_countries_analysis))
    n_sensitivity_countries = 20
    sens_path = out / "sensitivity_grid.csv"
    if sens_path.exists():
        try:
            sens_df = pd.read_csv(sens_path, usecols=["country_m49"])
            if not sens_df.empty:
                n_sensitivity_countries = int(sens_df["country_m49"].nunique())
        except Exception:
            logger.warning("Could not parse sensitivity_grid.csv country set; keeping default scope count.")

    coverage_section = (
        f"- Input panel coverage: {n_countries_input or '?'} countries, years "
        f"{config.BASE_YEAR}-{config.END_YEAR}, {n_species or '?'} species\n"
        f"- Interval-analysis coverage (Shapley + optimisation): {n_countries_analysis or '?'} countries\n"
        f"- Countries excluded from interval analyses due to active-share NaN intensity at endpoints: {n_excluded_analysis}"
    )

    optimisation_scope_section = (
        "- `Table4_optimization.csv` is ranked from `robust_optimization_results.csv` "
        "by `absolute_reduction_kt` (descending) over all analysed countries.\n"
        f"- `sensitivity_grid.csv` is computed on the top {n_sensitivity_countries} producers only "
        "(runtime-control subset used for parameter grid sweeps)."
    )
    opt_audit_path = out / "robust_optimization_audit.json"
    if opt_audit_path.exists():
        try:
            with open(opt_audit_path, "r", encoding="utf-8") as f:
                opt_audit = json.load(f)
            optimisation_transparency_section = (
                "- `robust_optimization_results.csv` preserves both export-safe raw (`raw_*`) and final (`optimized_*`) outputs.\n"
                "- `no_harm_excess_raw` records unconstrained overshoot relative to baseline before guard enforcement.\n"
                f"- Do-no-harm applied to {opt_audit.get('n_no_harm_applied', 'N/A')} / {opt_audit.get('n_countries', 'N/A')} countries.\n"
                f"- Negative reductions: raw={opt_audit.get('n_negative_raw_reductions', 'N/A')}, "
                f"final={opt_audit.get('n_negative_final_reductions', 'N/A')}.\n"
                "- Full traceability file: `outputs/robust_optimization_audit.json`."
            )
        except Exception:
            logger.warning("Could not parse robust_optimization_audit.json; using fallback transparency text.")
            optimisation_transparency_section = (
                "- `robust_optimization_results.csv` preserves both raw (`raw_*`) and final (`optimized_*`) outputs.\n"
                "- `no_harm_applied` flags where the guard changed the unconstrained solution."
            )
    else:
        optimisation_transparency_section = (
            "- `robust_optimization_results.csv` preserves both raw (`raw_*`) and final (`optimized_*`) outputs.\n"
            "- `no_harm_applied` flags where the guard changed the unconstrained solution."
        )

    from methane_portfolio import __version__

    text = _TEMPLATE.format(
        intensity_file=config.EMISSION_INTENSITY_FILE,
        structure_file=config.SPECIES_STRUCTURE_FILE,
        agg_file=config.COUNTRY_INTENSITY_FILE,
        coverage_section=coverage_section,
        base_year=config.BASE_YEAR,
        end_year=config.END_YEAR,
        share_tol=config.SHARE_SUM_TOL,
        share_status=share_status,
        milk_tol=config.MILK_MATCH_REL_TOL,
        milk_status=milk_status,
        identity_tol=config.IDENTITY_TOL,
        identity_status=identity_status,
        recon_tol=config.SHAPLEY_RECON_TOL,
        global_struct=global_struct,
        global_within=global_within,
        regime_year=config.REGIME_SHIFT_YEAR,
        chains=config.CHAINS,
        draws=config.DRAWS,
        tune=config.TUNE,
        target_accept=config.TARGET_ACCEPT,
        pymc_seed=config.PYMC_SEED,
        diagnostics_section=diagnostics_section,
        ppc_diagnostics_section=ppc_diagnostics_section,
        lam=0.5,
        opt_alpha=0.90,
        delta=0.10,
        optimisation_scope_section=optimisation_scope_section,
        optimisation_transparency_section=optimisation_transparency_section,
        kappa=config.DIRICHLET_KAPPA,
        n_draws=config.N_DIRICHLET_DRAWS,
        disclaimer=causal_disclaimer(),
        rng_seed=config.RNG_SEED,
        version=__version__,
    )

    p = out / "methods_appendix.md"
    p.write_text(text, encoding="utf-8")
    logger.info("Methods appendix written to %s", p)
    return p
